
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Web Stream</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
        }
        #videoContainer {
            max-width: 800px;
            width: 100%;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        video {
            width: 100%;
            height: auto;
        }
    </style>
</head>
<body>
    <div id="videoContainer">
        <video id="liveStream" autoplay playsinline>
            Your browser does not support the video tag.
        </video>
    </div>

    <script>
        // Load face-api.js library
        const script = document.createElement('script');
        script.src = 'https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js';
        document.head.appendChild(script);

        script.onload = async () => {
            // Load the face detection models
            await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('/models');

            // Create a canvas element for drawing facial landmarks
            const canvas = faceapi.createCanvasFromMedia(video);
            document.body.append(canvas);
            const displaySize = { width: video.width, height: video.height };
            faceapi.matchDimensions(canvas, displaySize);

            // Detect faces and draw landmarks
            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                faceapi.draw.drawDetections(canvas, resizedDetections);
                faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
            }, 100);
        };
        
        const video = document.getElementById('liveStream');

        async function startStream() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                video.srcObject = stream;
            } catch (err) {
                console.error("Error accessing the camera and microphone:", err);
            }
        }

        startStream();
    </script>
</body>
</html>
